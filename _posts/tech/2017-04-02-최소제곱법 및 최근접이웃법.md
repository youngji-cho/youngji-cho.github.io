---
layout: post
title: "최소제곱법 및 최근접 이웃법"
author: "youngji"
date: '2017-04-02'
categories: 'tech'
---

최소제곱법은 회귀분석에 기초한 정형화된 예측을 수행하는 반면에, 최근접 이웃법은 비정형 데이터 분석에 유리하다. 개인적으로 최근접이웃법은 특정한 값을 예측하는 것이 아니라, 분류(category)를 정하는데 더 요긴하게 쓰일 수 있다고 생각한다.

## 최소제곱법(Least Square)

최소제곱법은 통계분석에서 선형회귀분석의 기초가 된다. 실제 결과값 y에서 가장 가까운 선형회귀방정식 $\hat{y}$의 방정식을 찾아야 한다. 아래와 같은 식으로 나타낼수 있다.(다중회귀분석일 경우 x와 $\beta_1$는 벡터가 된다.)

$$\hat{y_i}=\beta_0+B_{1}x_i $$
여기서 $\hat{y}$과 실제값 y간의 오차를 잔차(residual)라고 하며, 각 변수 i마다 잔차의 제곱의 합이 최소되는 선형방정식 계수 $\beta_0, \beta_1$을 찾는 것이 최소제곱법의 목표이다.최소제곱법의 식은 아래와 같이 나타낼 수 있다.   

$$
\sum_{i=1}^n(\hat{y_i}-\beta_0-B_{1}x_i)^2 \\
\frac{\sigma}{\sigma\beta_0}\sum_{i=1}^n(\hat{y_i}-\beta_0-B_{1}x_i)^2\\
\frac{\sigma}{\sigma\beta_1}\sum_{i=1}^n(\hat{y_i}-\beta_0+B_{1}x_i)^2
$$

여기서 최소가 되는 $\beta_0, \beta_1$의 값은 각변수를 편미분한 값이 0이 되는 계수를 찾으면 되고, 편미분 방정식을 정리를 하면 행렬의 곱셈으로 나타낼수 있다. 세부적인 증명의 [나의 미디엄]("https://medium.com/@youngji/%EC%B5%9C%EC%86%8C%EC%A0%9C%EA%B3%B1%EB%B2%95-least-squared-method-f7357990329f")을 참고하길 바란다.

다음은 r에서 가장 기초적인 데이터셋인 mtcars을 통해 무게(Weight)와 연비(Mile Per Gallon)간의 관계를 알아보겠다. 파란색 점과 빨간색 점의 거리의 차이가 잔차(residual)이고, 잔차를 최소화하는 선형방정식의 계수를 구하는 것이 최소제곱법이다.


```r
mtcars1<-arrange(mtcars,wt)
fit<-lm(mpg~wt,data=mtcars1)
fit$coefficients
```

```
## (Intercept)          wt
##   37.285126   -5.344472
```

최소제곱법을 통한 예측값에서 $\beta_0$는 37.28이고, $\beta_1$은 -5.34이다.이러한 모델에서 최소화되는 잔차, 즉 오차들은 아래와 같다.(mtcars는 32행의 데이터이다.)


```r
fit$residuals
```

```
##          1          2          3          4          5          6
##  1.2010593  1.7461954  6.4219792  0.3564263  0.1520430  6.8727113
##          7          8          9         10         11         12
## -2.0859521 -2.6110037 -2.2826106 -2.7809399 -1.0274952 -0.9197704
##         13         14         15         16         17         18
##  2.3499593 -4.5431513  4.1637381  1.2973499 -3.7268663 -0.2001440
##         19         20         21         22         23         24
##  0.2998560 -1.1001440 -0.6932545 -2.9725862 -3.9053627 -3.2053627
##         25         26         27         28         29         30
## -0.0502472 -1.8830236 -3.4623553  2.4643670  0.8668731  1.1733496
##         31         32
##  5.9810744  2.1032876
```

이러한 실제값과 예측값의 차이를 그래프로 나타내보겠다. 그래프와 점간의 y의 값과 평행인 직선을 내렸을때 직선의 길이가 잔차(residual)이다.

![plot of chunk LS](/figureLS-1.png)

## 최근접이웃법(Nearest Neighbor)

최근접 이웃법은 최소제곱법과 같이 "거리(distance)"를 이용하지만 조금 다른 예측을 한다. 최근접이웃은 예측값에 얼만큼 가까운지에 대해서 나타낸다. 최접근이웃은 비선형적인 예측을 하기 때문에, 특정수치를 예측하기 보다는 범주를 규정하는데 많이 사용한다. Mtcars 데이터에서 마지막 데이터인 Volvo 142E의 자동변속기 장착여부(am)를 모른다고 가정을 해보자. 과연 Volvo 142E의 변속기는 자동(1)일까 아니면 수동(0)일까?

![plot of chunk KNN1](/figureKNN1-1.png)

Volvo 142E는 실제로 자동변속기를 사용하고, 그래프를 언뜻보기에 자동변속기(am=1)인 데이터들과 가까이 있으므로, 자동이라고 유추할 수 있다. 이러한 논증을 보다 체계적으로 수행하는 것이 최근접 이웃법이다.

최근접 이웃법에서 "거리"는 "유클리드거리($d=\sqrt{a^2+b^2}$)"를 의미하며, 가장 가까운 k개의 점을 골라서 예측값이 어떤 집단에 가까운지를 파악한다. p차원의 데이터 $x_i$가 있다고 하자. $x_i$의 좌표값은 $(x_{i1},x_{i2} \cdots x_{ip})$이다. $x_i, x_l$간의 거리(d)의 수식은 아래와 같이 나타낼 수 있다.

$$
d(x_i,x_l) = \sqrt{(x_{i1}-x_{l1})^2 + (x_{i2}-x_{l2})^2 + \cdots + (x_{ip}-x_{lp})^2}
$$

예측하고자 하는 점에서 가장 거리가 가까운 점을 찾아서 그 점들의 범주를 분석을 해서 예측값의 분류를 결정한다. 앞선 mtcars은 2차원 데이터 였으니 , $\sqrt{(x_{i1}-x_{l1})^2 +  (x_{i2}-x_{l2})^2}$가 거리의 방정식이다. k에 따라 가까운 거리의 합산과 예측값이 바뀔 수 있으며, K값을 설정하는 것은 매우 중요하다.

최근접이웃법은 KNN(K Nearest Neighbor)라고도 부른다. "K"는 핵심적인 계수로, 최근접값을 몇개를 기준으로 측정을 할지 결정한다. 앞선 예에서 Volvo 142E의 변속기가 수동인지 자동인지 예측해보자, 실제로 Volvo 142E는 자동변속기(1)를 쓴다. 실제로 맞춘 k의 값은 "2,3,6,7"이다. 이러한 지속적인 validation으로 적합한 k값을 찾아야 한다.


```r
mtcars2[32,3]=1
x<-1:31;y<-32
train<-mtcars2[x,1:2]
test<-mtcars2[y,1:2]
cl<-factor(mtcars2[x,3])
ans<-data.frame(vector("numeric"),vector("numeric"),vector("numeric"))
for(k in 10:1){
 knn_fit<-knn(train,test,cl,k)
 x<-cbind.data.frame(k,knn_fit,mtcars2[y,3])
 ans<-rbind.data.frame(x,ans,deparse.level = 2)
}
names(ans)<-c("K의 계수","KNN 예측값","실제값")
ans
```

```
##    K의 계수 KNN 예측값 실제값
## 1         1          0      1
## 2         2          0      1
## 3         3          1      1
## 4         4          0      1
## 5         5          0      1
## 6         6          1      1
## 7         7          1      1
## 8         8          1      1
## 9         9          0      1
## 10       10          0      1
```

## 마치며

최소제곱법과 최근접이웃법은 정형/비정형 데이터를 분석하는 기초적인 방법이다. 원리도 생각보다 간단하다. 물론 실제 예측할때는 앞선 예에서 처럼 단순한 2차원 데이터가 아니라 다차원 일 경우가 많고, 예측하고자 하는 값도 1개아 아니라 여러개이기 때문에 정말로 많은 Validation이 필요하다.
